---
layout: page
title: How I Read Newsletters
---

---

During my stint in graduate school I learned that one of the most difficult parts of scientific work is keeping up with the flood of new research. It's one thing to know the literature of your field, it's an entirely different thing to keep up with it. You simply cannot read everything new that's relevant, however if you don't keep up you can never be sure you're doing important work. So how does one keep up?

At the time, I adopted the approach of the [Leek Research Group](http://jtleek.com/) ([documented here on github](https://github.com/jtleek/readingpapers)). I'd summarize it as setting up a firehose of good sources and then regularly skimming and filtering it at different levels. First the title, then the key take-aways, then the evidence behind those take-aways. Finally, if a paper has managed to maintain your interest through all of that, you read the whole thing.

This is a wild shift from the way we are taught to read, i.e. deeply for understanding, but the goal here isn't to understand every detail. The goal is to build a mental model of what's happening and how everything fits together. Over time your filters grow stronger and you develop an eye for where things are going. This is invaluable when working in a fast changing field.

After I moved out of academia I took this habit with me but adapted it for working in data science and engineering. Below I've rewritten Leek's guide from this perspective.

---

## Why should you keep up?

Most importantly you're filling in a mental map of what you know and what you know you don't know. The smaller you can make the space of things you don't know you don't know the better. Even skimming titles adds to this map. You're bombarding yourself with problems, solutions, approaches, packages, trends and more. When a new problem falls on your desk there's a good chance you'll at least know where to go to learn more. Simply knowing where to start or that a solution exists is a massive head start.

## What should you read / listen / watch?

In my opinion, for someone working in the average applied data role, the best content is currently coming from blogs, podcasts, and newsletters. This is where real people talk about solving real problems. Startup tech blogs, consulting firms, and venture capital firms also tend to produce some good stuff. For more cutting-edge research, arXiv and the standard applied data/statistics journals should be on your radar. There's also nothing better than a great conference or Meetup talk when you find one.

## How should you find content?

Since a lot of these sources are poorly aggregated you need something to help expose you to new content and sources. A fantastic solution for this has become curated newsletters. [Newsletters are booming](https://medium.com/the-mission/how-on-earth-did-email-newsletters-become-popular-again-3fcee1addc7e). They are often run by opinionated folks in much the same way great blogs are. The curator reads a ton of content, picks out their favorites and sends them to you. Whenever you find a great blog, podcast, etc., subscribe directly.

Other ways of finding content include following those who produce great stuff on platforms like Twitter or Youtube. Subreddit communities can be great as well. Given my current work, I very rarely skim through journals but when a big journal article drops everyone is talking about it and it comes onto my radar one way or another.

One last note on sources is that you should always be culling the herd. Unsubscribe if any of them stop producing good content or if it's better for you to get their content pre-filtered by something like a newsletter.

## How much should you consume?

**This is the most important part.** After subscribing to a starter batch of sources you need to change the way you read and create a new workflow for getting through it. I'd suggest sitting down once a week and going through everything new at once.

Open each source and read every title. Open titles that interest you in new tabs. After you've gotten through all the sources start skimming through tabs. Do everything in batches.

A rough guideline on how much to read:
- **100%** - Read the title
- **10-20%** - Skim the article/docs or sample the ~5 mins of the podcast/video
- **1-5%** - Read/listen/watch the entire article/podcast/video
- **<1%** - Save for future reference

You need to be a brutal, critical judge. If the sample code is bad, stop and move on. If the writer's logic is poor, stop and move on. If a podcast guest is clearly unknowledgeable, stop and move on. You'll develop different red flags for different types of content.

When you find something good enough to save try to really understand it. Find the there there, the first principles. Then think about how broadly it applies outside the context of the source and how it fits into what you already know.

One last note is that over time you will develop stronger and stronger filters which speeds everything up. Most things are simply over-hyped, over-sold, or aren't relevant to your day-to-day. It's ok to skip them. It's often more than enough to just know something exists.

## Then what?

When you find gold, stash it! In school I used [Zotero](https://www.zotero.org/) and [Feedly](https://feedly.com/i/welcome). Some folks blast everything out on Twitter and others like good old-fashioned bookmarks. Note-keeping apps like [Evernote](https://evernote.com/), [Keep](https://keep.google.com), or [Journal](https://usejournal.com/) can also be good solutions.
